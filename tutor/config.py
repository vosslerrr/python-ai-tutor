MODEL_PATH = "tutor/models/qwen2.5-3b-instruct-q4_k_m.gguf"

# llama.cpp model settings
N_CTX = 4096
N_THREADS = 8
N_GPU_LAYERS = 0

# tutor behavior
MAX_TOKENS = 350
TEMPERATURE = 0.6
TOP_P = 0.95

# UI-friendly formatting
STRUCTURED_OUTPUT = True